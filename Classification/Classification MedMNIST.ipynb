{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbQWL5WznhJS"
   },
   "source": [
    "# Bayes by Backprop\n",
    "\n",
    "APPLICATION TO MedMNIST DATASETS  https://medmnist.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yNGUXrL_osEt"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "sns.set()\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_palette(\"muted\")\n",
    "sns.set_color_codes(\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "print(f\"MedMNIST v{medmnist.__version__} @ {medmnist.HOMEPAGE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1528263793235,
     "user": {
      "displayName": "Nitarshan Rajkumar",
      "photoUrl": "//lh6.googleusercontent.com/-oLz5q0aJmAQ/AAAAAAAAAAI/AAAAAAAAAIY/O0-NjvATt18/s50-c-k-no/photo.jpg",
      "userId": "117587045527370134083"
     },
     "user_tz": 420
    },
    "id": "oGXTNl-Vt7PF",
    "outputId": "d53f7e66-2071-43f4-ac11-9589ba4846c2"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"device\", DEVICE)\n",
    "LOADER_KWARGS = {'num_workers': 1, 'pin_memory': True} if torch.backends.mps.is_available() else {}\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-N2EKVF_muVQ"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_flag = 'dermamnist'\n",
    "download = True\n",
    "\n",
    "NUM_EPOCHS = 200\n",
    "BATCH_SIZE = 91\n",
    "TEST_BATCH_SIZE = 401\n",
    "lr = 0.001\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "# load the data\n",
    "train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
    "test_dataset = DataClass(split='test', transform=data_transform, download=download)\n",
    "\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset)\n",
    "print(\"===================\")\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = len(train_dataset)\n",
    "TEST_SIZE = len(test_loader.dataset)\n",
    "NUM_BATCHES = len(train_loader)\n",
    "NUM_TEST_BATCHES = len(test_loader)\n",
    "\n",
    "print(TRAIN_SIZE)\n",
    "print(TEST_SIZE)\n",
    "\n",
    "CLASSES = 7\n",
    "SAMPLES = 2\n",
    "TEST_SAMPLES = 10\n",
    "\n",
    "assert (TRAIN_SIZE % BATCH_SIZE) == 0\n",
    "assert (TEST_SIZE % TEST_BATCH_SIZE) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q9-GjqfnozFI"
   },
   "outputs": [],
   "source": [
    "class Gaussian(object):\n",
    "    def __init__(self, mu, rho):\n",
    "        super().__init__()\n",
    "        self.mu = mu\n",
    "        self.rho = rho\n",
    "        self.normal = torch.distributions.Normal(0,1)\n",
    "    \n",
    "    @property\n",
    "    def sigma(self):\n",
    "        return torch.log1p(torch.exp(self.rho))\n",
    "    \n",
    "    def sample(self):\n",
    "        epsilon = self.normal.sample(self.rho.size()).to(DEVICE)\n",
    "        return self.mu + self.sigma * epsilon\n",
    "    \n",
    "    def log_prob(self, input):\n",
    "        return (-math.log(math.sqrt(2 * math.pi))\n",
    "                - torch.log(self.sigma)\n",
    "                - ((input - self.mu) ** 2) / (2 * self.sigma ** 2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "L3wQlWNVo3S_"
   },
   "outputs": [],
   "source": [
    "class ScaleMixtureGaussian(object):\n",
    "    def __init__(self, pi, sigma1, sigma2):\n",
    "        super().__init__()\n",
    "        self.pi = pi\n",
    "        self.sigma1 = sigma1\n",
    "        self.sigma2 = sigma2\n",
    "        self.gaussian1 = torch.distributions.Normal(0,sigma1)\n",
    "        self.gaussian2 = torch.distributions.Normal(0,sigma2)\n",
    "    \n",
    "    def log_prob(self, input):\n",
    "        prob1 = torch.exp(self.gaussian1.log_prob(input))\n",
    "        prob2 = torch.exp(self.gaussian2.log_prob(input))\n",
    "        return (torch.log(self.pi * prob1 + (1-self.pi) * prob2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31782,
     "status": "ok",
     "timestamp": 1528263837119,
     "user": {
      "displayName": "Nitarshan Rajkumar",
      "photoUrl": "//lh6.googleusercontent.com/-oLz5q0aJmAQ/AAAAAAAAAAI/AAAAAAAAAIY/O0-NjvATt18/s50-c-k-no/photo.jpg",
      "userId": "117587045527370134083"
     },
     "user_tz": 420
    },
    "id": "fzTq5zWgo5p8",
    "outputId": "cc845c99-ce8d-4cbe-f79a-c0fd4ee72e63"
   },
   "outputs": [],
   "source": [
    "#PI = 0.5\n",
    "#SIGMA_1 = torch.FloatTensor([math.exp(-0)]).to(DEVICE)\n",
    "#SIGMA_2 = torch.FloatTensor([math.exp(-6)]).to(DEVICE)\n",
    "\n",
    "# BBB prior for 400 units\n",
    "PI = 0.25\n",
    "SIGMA_1 = torch.FloatTensor([math.exp(-1)]).to(DEVICE)\n",
    "SIGMA_2 = torch.FloatTensor([math.exp(-6)]).to(DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ju2J8fneo7kc"
   },
   "outputs": [],
   "source": [
    "class BayesianLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        # Weight parameters\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-0.2, 0.2))\n",
    "        #self.weight_rho = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-5,-4))\n",
    "\n",
    "        # BBB\n",
    "        self.weight_rho = nn.Parameter(torch.Tensor(out_features, in_features).normal_(-8, .05))\n",
    "        \n",
    "        self.weight = Gaussian(self.weight_mu, self.weight_rho)\n",
    "        \n",
    "        # Bias parameters\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features).uniform_(-0.2, 0.2))\n",
    "        #self.bias_rho = nn.Parameter(torch.Tensor(out_features).uniform_(-5,-4))\n",
    "\n",
    "        # BBB\n",
    "        self.bias_rho = nn.Parameter(torch.Tensor(out_features).normal_(-8, .05))\n",
    "    \n",
    "\n",
    "        self.bias = Gaussian(self.bias_mu, self.bias_rho)\n",
    "\n",
    "        # Prior distributions\n",
    "        self.weight_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
    "        self.bias_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
    "        self.log_prior = 0\n",
    "        self.log_variational_posterior = 0\n",
    "\n",
    "    def forward(self, input, sample=False, calculate_log_probs=False):\n",
    "        if self.training or sample:\n",
    "            weight = self.weight.sample()\n",
    "            bias = self.bias.sample()\n",
    "        else:\n",
    "            weight = self.weight.mu\n",
    "            bias = self.bias.mu\n",
    "        if self.training or calculate_log_probs:\n",
    "            self.log_prior = self.weight_prior.log_prob(weight) + self.bias_prior.log_prob(bias)\n",
    "            self.log_variational_posterior = self.weight.log_prob(weight) + self.bias.log_prob(bias)\n",
    "        else:\n",
    "            self.log_prior, self.log_variational_posterior = 0, 0\n",
    "\n",
    "        return F.linear(input, weight, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "itSuNJtYo-X7"
   },
   "outputs": [],
   "source": [
    "class BayesianNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # for 28*28 RGB (3) IMAGES\n",
    "        self.l1 = BayesianLinear(3*28*28, 400)\n",
    "        self.l2 = BayesianLinear(400, 400)\n",
    "        self.l3 = BayesianLinear(400, 7)\n",
    "    \n",
    "    def forward(self, x, sample=False):\n",
    "        x = x.view(-1, 3*28*28)\n",
    "        x = F.relu(self.l1(x, sample))\n",
    "        x = F.relu(self.l2(x, sample))\n",
    "        x = F.log_softmax(self.l3(x, sample), dim=1)\n",
    "        return x\n",
    "    \n",
    "    def log_prior(self):\n",
    "        return self.l1.log_prior \\\n",
    "               + self.l2.log_prior \\\n",
    "               + self.l3.log_prior\n",
    "    \n",
    "    def log_variational_posterior(self):\n",
    "        return self.l1.log_variational_posterior \\\n",
    "               + self.l2.log_variational_posterior \\\n",
    "               + self.l3.log_variational_posterior\n",
    "    \n",
    "    def sample_elbo(self, input, target, samples=SAMPLES):\n",
    "        \n",
    "        outputs = torch.zeros(samples, BATCH_SIZE, CLASSES).to(DEVICE)\n",
    "        log_priors = torch.zeros(samples).to(DEVICE)\n",
    "        log_variational_posteriors = torch.zeros(samples).to(DEVICE)\n",
    "        for i in range(samples):\n",
    "            outputs[i] = self(input, sample=True)\n",
    "            log_priors[i] = self.log_prior()\n",
    "            log_variational_posteriors[i] = self.log_variational_posterior()\n",
    "        log_prior = log_priors.mean()\n",
    "        log_variational_posterior = log_variational_posteriors.mean()\n",
    "        negative_log_likelihood = F.nll_loss(outputs.mean(0), target, size_average=False)\n",
    "        loss = (log_variational_posterior - log_prior)/NUM_BATCHES + negative_log_likelihood\n",
    "        return loss, log_prior, log_variational_posterior, negative_log_likelihood\n",
    "\n",
    "net = BayesianNetwork().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h-HLpkfPm2BI"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q31y405kpGxt"
   },
   "outputs": [],
   "source": [
    "def train(net, optimizer, epoch):\n",
    "    net.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        target = target.squeeze().long()\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        net.zero_grad()\n",
    "        loss, log_prior, log_variational_posterior, negative_log_likelihood = net.sample_elbo(data, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, samples):\n",
    "    correct = 0\n",
    "    for idx, (data, target) in enumerate(loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        if samples == 1:\n",
    "            output = model(data, sample=False).to(DEVICE)\n",
    "        else:\n",
    "            outputs = torch.zeros(samples, TEST_BATCH_SIZE, CLASSES).to(DEVICE)\n",
    "            for i in range(samples):\n",
    "                outputs[i] = model(data, sample=True)\n",
    "            output = outputs.mean(0)\n",
    "\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1090232,
     "status": "ok",
     "timestamp": 1528264929340,
     "user": {
      "displayName": "Nitarshan Rajkumar",
      "photoUrl": "//lh6.googleusercontent.com/-oLz5q0aJmAQ/AAAAAAAAAAI/AAAAAAAAAIY/O0-NjvATt18/s50-c-k-no/photo.jpg",
      "userId": "117587045527370134083"
     },
     "user_tz": 420
    },
    "id": "cWaZ4c93pJkm",
    "outputId": "379e274f-ac3b-406b-9d31-c1a760242f84"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "#optimizer = optim.Adam(net.parameters())\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-4, momentum=0.95)\n",
    "\n",
    "test_accs_ens = np.zeros(200)\n",
    "test_accs_mean = np.zeros(200)\n",
    "\n",
    "for epoch in range(200):\n",
    "    train(net, optimizer, epoch)\n",
    "    if epoch%5 == 0:\n",
    "        test_acc_ens = evaluate(net, test_loader, samples=10)\n",
    "        test_acc_mean = evaluate(net, test_loader, samples=1)\n",
    "        test_accs_ens[epoch] = test_acc_ens\n",
    "        test_accs_mean[epoch] = test_acc_mean\n",
    "        print('Epoch: ', epoch)\n",
    "        print('Test acc ens: ', test_acc_ens)\n",
    "        print('Test acc mean: ', test_acc_mean)\n",
    "\n",
    "    if epoch%50 == 0:\n",
    "        path = 'Results/med/BBB_derma_400_0.0001_ID0_notebook_epoch_' + str(epoch)\n",
    "        torch.save(net.state_dict(), path + '.pth')\n",
    "\n",
    "path = 'Results/med/BBB_derma_400_0.0001_ID0_notebook_epoch_' + str(epoch)\n",
    "torch.save(net.state_dict(), path + '.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Results/med/BBB_derma_400_0.0001_ID0_notebook'\n",
    "wr = csv.writer(open(path + '.csv', 'w'), delimiter=',', lineterminator='\\n')\n",
    "wr.writerow(['epoch', 'test_acc_ens', 'test_acc_mean'])\n",
    "\n",
    "for i in range(200):\n",
    "    wr.writerow((i + 1, test_accs_ens[i] ,test_accs_mean[i] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LwmjhEqlm64B"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6zoJviDmArm"
   },
   "source": [
    "### Model Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are building an enseble of 10 samples. Each component is a sample and we resample weights and biases. For each component we evaluate accuracy. what we obtain as posterior mean accuracy is not resampling weights and biases (used from eman weights like effectively feeding data to our model). Ensemble accuracy is the mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"Results/med/BBB_derma_400_0.0001_ID0_notebook_epoch_199.pth\"\n",
    "\n",
    "model = BayesianNetwork().to(DEVICE)\n",
    "\n",
    "model.load_state_dict(torch.load(modelpath, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 198116,
     "status": "ok",
     "timestamp": 1528265127612,
     "user": {
      "displayName": "Nitarshan Rajkumar",
      "photoUrl": "//lh6.googleusercontent.com/-oLz5q0aJmAQ/AAAAAAAAAAI/AAAAAAAAAIY/O0-NjvATt18/s50-c-k-no/photo.jpg",
      "userId": "117587045527370134083"
     },
     "user_tz": 420
    },
    "id": "j4OzjvLHpL3o",
    "outputId": "1a8164fc-85d0-4b08-e010-33c3b7322b09"
   },
   "outputs": [],
   "source": [
    "def test_ensemble(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    corrects = np.zeros(TEST_SAMPLES+1, dtype=int)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            outputs = torch.zeros(TEST_SAMPLES+1, TEST_BATCH_SIZE, CLASSES).to(DEVICE)\n",
    "            for i in range(TEST_SAMPLES):\n",
    "                # for BBB is infer for notebook is sample\n",
    "                outputs[i] = model(data, sample=True)\n",
    "            outputs[TEST_SAMPLES] = model(data, sample=False)\n",
    "            output = outputs.mean(0)\n",
    "            preds = preds = outputs.max(2, keepdim=True)[1]\n",
    "            pred = output.max(1, keepdim=True)[1] # index of max log-probability\n",
    "            corrects += preds.eq(target.view_as(pred)).sum(dim=1).squeeze().cpu().numpy()\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    for index, num in enumerate(corrects):\n",
    "        if index < TEST_SAMPLES:\n",
    "            print('Component {} Accuracy: {}/{}'.format(index, num, TEST_SIZE))\n",
    "        else:\n",
    "            print('Posterior Mean Accuracy: {}/{}'.format(num, TEST_SIZE))\n",
    "    print('Ensemble Accuracy: {}/{}'.format(correct, TEST_SIZE))\n",
    "\n",
    "test_ensemble(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating ECE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_one_hot(targets, nb_classes):\n",
    "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
    "    return res.reshape(list(targets.shape)+[nb_classes])\n",
    "\n",
    "def forward_ece( probs, labels):\n",
    "        pred_class = np.argmax(probs, axis=1)\n",
    "        print(pred_class)\n",
    "\n",
    "        # make confidence, preds, labels one-hot\n",
    "        expanded_preds = np.reshape(probs, -1)\n",
    "        print(expanded_preds)\n",
    "        pred_class_OH = np.reshape(get_one_hot(pred_class, 7), -1)\n",
    "       \n",
    "        target_class_OH = np.reshape(get_one_hot(labels, 7), -1)\n",
    "        correct_vec = (target_class_OH*(pred_class_OH == target_class_OH)).astype(int)\n",
    "\n",
    "        # generate bins\n",
    "        bins = np.arange(0, 1.1, 0.1)\n",
    "        bin_idxs = np.digitize(abs(expanded_preds), bins, right=True)\n",
    "        print(bin_idxs)\n",
    "        bin_idxs = bin_idxs - 1\n",
    "        \n",
    "        bin_centers = bins[1:] - 10/2\n",
    "        print(bin_centers)\n",
    "        bin_counts = np.ones(len(bin_centers))\n",
    "        bin_corrects = np.zeros(len(bin_centers))\n",
    "        bin_confidence = np.zeros(len(bin_centers))\n",
    "\n",
    "        min_idx = 10\n",
    "        if min(bin_idxs) < min_idx:\n",
    "            min_idx = min(bin_idxs)\n",
    "        \n",
    "        for nbin in range(len(bin_centers)):\n",
    "            bin_counts[nbin] = np.sum((bin_idxs==nbin).astype(int))\n",
    "            bin_corrects[nbin] = np.sum(correct_vec[bin_idxs==nbin])\n",
    "            bin_confidence[nbin] = np.mean(expanded_preds[bin_idxs==nbin])\n",
    "\n",
    "        have_data = bin_counts > 0  \n",
    "        bin_acc = bin_corrects[have_data] / bin_counts[have_data]\n",
    "\n",
    "        ece = 0\n",
    "        for i in range(len(bin_acc)):\n",
    "            ece += np.absolute(bin_confidence[i]-bin_acc[i]) * bin_counts[i]/np.sum(bin_counts)\n",
    "\n",
    "        return ece, bin_centers[have_data], bin_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eces = []\n",
    "confidence_lists = []\n",
    "accuracy_lists =[]\n",
    "\n",
    "TEST_SAMPLES = 20\n",
    "\n",
    "with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            outputs = torch.zeros(TEST_SAMPLES+1, TEST_BATCH_SIZE, CLASSES).to(DEVICE)\n",
    "            for i in range(TEST_SAMPLES):\n",
    "                # for BBB is infer for notebook is sample\n",
    "                outputs[i] = model(data, sample=True)\n",
    "            outputs[TEST_SAMPLES] = model(data, sample=False)\n",
    "            output = outputs.mean(0)\n",
    "            ece, confidence_list, accuracy_list = forward_ece(np.array(output.cpu().numpy()), np.array(target.cpu().numpy()))\n",
    "            eces.append(ece)\n",
    "            confidence_lists.append(confidence_list)\n",
    "            accuracy_lists.append(accuracy_list)\n",
    "\n",
    "mean_acc = np.array(accuracy_lists).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-colorblind')\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(np.arange(0.05, 1.0, 0.1), mean_acc, marker='o', linewidth=2, color=\"#4C0099\" )\n",
    "plt.plot([0.05, 0.95], [0.05, 0.95], '--', linewidth=2, label = 'Ideal', color = 'red')\n",
    "plt.legend(loc=2, prop={'size': 15})\n",
    "plt.xlabel('Confidence', fontsize=15)\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xticks(np.arange(0.05, 1.0, 0.1), fontsize=10)\n",
    "plt.savefig('reliability_diagram.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Xa8bwZcnO2R"
   },
   "source": [
    "### Model Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"Results/med/BBB_derma_1200_0.0001_ID1_notebook_new_epoch_299.pth\"\n",
    "\n",
    "model = BayesianNetwork().to(DEVICE)\n",
    "\n",
    "model.load_state_dict(torch.load(modelpath, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qwd_xrtqpsvJ"
   },
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "sample = next(dataiter)\n",
    "print(sample[1][10:15])\n",
    "\n",
    "sample = sample[0][10:15].to(DEVICE)\n",
    "\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "Grid = make_grid(sample.cpu(), padding = 5, nrows = 1)\n",
    "show(Grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2293,
     "status": "ok",
     "timestamp": 1528265133412,
     "user": {
      "displayName": "Nitarshan Rajkumar",
      "photoUrl": "//lh6.googleusercontent.com/-oLz5q0aJmAQ/AAAAAAAAAAI/AAAAAAAAAIY/O0-NjvATt18/s50-c-k-no/photo.jpg",
      "userId": "117587045527370134083"
     },
     "user_tz": 420
    },
    "id": "PBxwd31ppwIo",
    "outputId": "4349ee1a-6102-4e84-daf5-fe7888db37e0"
   },
   "outputs": [],
   "source": [
    "\n",
    "#{'0': actinic keratoses and intraepithelial carcinoma, '1': 'basal cell carcinoma', '2': 'benign keratosis-like lesions', \n",
    "# '3': 'dermatofibroma', '4': 'melanoma', '5': 'melanocytic nevi', '6': 'vascular lesions'}\n",
    "\n",
    "\n",
    "net.eval()\n",
    "outputs = model(sample, True).max(1, keepdim=True)[1].detach().cpu().numpy()\n",
    "for _ in range(999):\n",
    "    outputs = np.append(outputs, model(sample, True).max(1, keepdim=True)[1].detach().cpu().numpy(), axis=1)\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "fig, ax = plt.subplots(5,1,figsize=(4,3))\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(5,1,i+1)\n",
    "    \n",
    "    plt.xlabel(\"Label\")\n",
    "    if i ==2:\n",
    "        plt.ylabel(\"Confidence\")\n",
    "    plt.yticks([])\n",
    "    plt.xticks(range(7), [\"0\", \"1\", \"2 \",\"3\", \"4\", \"5\", \"6\"])\n",
    "    plt.hist(outputs[i], np.arange(-0.5, 7, 1), color=\"#4C0099\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "bayes-by-backprop.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
