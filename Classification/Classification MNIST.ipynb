{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbQWL5WznhJS"
   },
   "source": [
    "# Bayes by Backprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yNGUXrL_osEt"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import csv\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "writer = SummaryWriter()\n",
    "sns.set()\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_palette(\"muted\")\n",
    "sns.set_color_codes(\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1528263793235,
     "user": {
      "displayName": "Nitarshan Rajkumar",
      "photoUrl": "//lh6.googleusercontent.com/-oLz5q0aJmAQ/AAAAAAAAAAI/AAAAAAAAAIY/O0-NjvATt18/s50-c-k-no/photo.jpg",
      "userId": "117587045527370134083"
     },
     "user_tz": 420
    },
    "id": "oGXTNl-Vt7PF",
    "outputId": "d53f7e66-2071-43f4-ac11-9589ba4846c2"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"device\", DEVICE)\n",
    "LOADER_KWARGS = {'num_workers': 1, 'pin_memory': True} if torch.backends.mps.is_available() else {}\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-N2EKVF_muVQ"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SMzSB6ebovaD"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 120\n",
    "TEST_BATCH_SIZE = 1000\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        './mnist', train=True, download=True,\n",
    "        transform=transforms.ToTensor()),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, **LOADER_KWARGS)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        './mnist', train=False, download=True,\n",
    "        transform=transforms.ToTensor()),\n",
    "    batch_size=TEST_BATCH_SIZE, shuffle=False, **LOADER_KWARGS)\n",
    "\n",
    "TRAIN_SIZE = len(train_loader.dataset)\n",
    "TEST_SIZE = len(test_loader.dataset)\n",
    "NUM_BATCHES = len(train_loader)\n",
    "NUM_TEST_BATCHES = len(test_loader)\n",
    "\n",
    "CLASSES = 10\n",
    "TRAIN_EPOCHS = 600\n",
    "SAMPLES = 2\n",
    "TEST_SAMPLES = 10\n",
    "\n",
    "assert (TRAIN_SIZE % BATCH_SIZE) == 0\n",
    "assert (TEST_SIZE % TEST_BATCH_SIZE) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q9-GjqfnozFI"
   },
   "outputs": [],
   "source": [
    "class Gaussian(object):\n",
    "    def __init__(self, mu, rho):\n",
    "        super().__init__()\n",
    "        self.mu = mu\n",
    "        self.rho = rho\n",
    "        self.normal = torch.distributions.Normal(0,1)\n",
    "    \n",
    "    @property\n",
    "    def sigma(self):\n",
    "        return torch.log1p(torch.exp(self.rho))\n",
    "    \n",
    "    def sample(self):\n",
    "        epsilon = self.normal.sample(self.rho.size()).to(DEVICE)\n",
    "        return self.mu + self.sigma * epsilon\n",
    "    \n",
    "    def log_prob(self, input):\n",
    "        return (-math.log(math.sqrt(2 * math.pi))\n",
    "                - torch.log(self.sigma)\n",
    "                - ((input - self.mu) ** 2) / (2 * self.sigma ** 2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "L3wQlWNVo3S_"
   },
   "outputs": [],
   "source": [
    "class ScaleMixtureGaussian(object):\n",
    "    def __init__(self, pi, sigma1, sigma2):\n",
    "        super().__init__()\n",
    "        self.pi = pi\n",
    "        self.sigma1 = sigma1\n",
    "        self.sigma2 = sigma2\n",
    "        self.gaussian1 = torch.distributions.Normal(0,sigma1)\n",
    "        self.gaussian2 = torch.distributions.Normal(0,sigma2)\n",
    "    \n",
    "    def log_prob(self, input):\n",
    "        prob1 = torch.exp(self.gaussian1.log_prob(input))\n",
    "        prob2 = torch.exp(self.gaussian2.log_prob(input))\n",
    "        return (torch.log(self.pi * prob1 + (1-self.pi) * prob2)).sum()\n",
    "\n",
    "\n",
    "\n",
    "class ScaleGaussian(object):\n",
    "    def __init__(self, pi, sigma1):\n",
    "        super().__init__()\n",
    "        self.pi = pi\n",
    "        self.sigma1 = sigma1\n",
    "        self.gaussian1 = torch.distributions.Normal(0,sigma1)\n",
    "\n",
    "    def log_prob(self, input):\n",
    "        prob1 = torch.exp(self.gaussian1.log_prob(input))\n",
    "        return (torch.log(prob1)).sum()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jwvLm9zGl3N7"
   },
   "source": [
    "$$\\pi = \\frac{1}{2}$$\n",
    "$$-\\ln{\\sigma_1} = 0$$\n",
    "$$-\\ln{\\sigma_2} = 6$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31782,
     "status": "ok",
     "timestamp": 1528263837119,
     "user": {
      "displayName": "Nitarshan Rajkumar",
      "photoUrl": "//lh6.googleusercontent.com/-oLz5q0aJmAQ/AAAAAAAAAAI/AAAAAAAAAIY/O0-NjvATt18/s50-c-k-no/photo.jpg",
      "userId": "117587045527370134083"
     },
     "user_tz": 420
    },
    "id": "fzTq5zWgo5p8",
    "outputId": "cc845c99-ce8d-4cbe-f79a-c0fd4ee72e63"
   },
   "outputs": [],
   "source": [
    "#PI = 0.5\n",
    "#SIGMA_1 = torch.FloatTensor([math.exp(-0)]).to(DEVICE)\n",
    "#SIGMA_2 = torch.FloatTensor([math.exp(-6)]).to(DEVICE)\n",
    "\n",
    "# BBB prior for 400 units\n",
    "PI = 0.25\n",
    "SIGMA_1 = torch.FloatTensor([math.exp(-1)]).to(DEVICE)\n",
    "SIGMA_2 = torch.FloatTensor([math.exp(-6)]).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ju2J8fneo7kc"
   },
   "outputs": [],
   "source": [
    "class BayesianLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, mixture):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.mixture = mixture\n",
    "        # Weight parameters\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-0.2, 0.2))\n",
    "        #self.weight_rho = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-5,-4))\n",
    "\n",
    "        # BBB\n",
    "        self.weight_rho = nn.Parameter(torch.Tensor(out_features, in_features).normal_(-8, .05))\n",
    "        \n",
    "        self.weight = Gaussian(self.weight_mu, self.weight_rho)\n",
    "        \n",
    "        # Bias parameters\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features).uniform_(-0.2, 0.2))\n",
    "        #self.bias_rho = nn.Parameter(torch.Tensor(out_features).uniform_(-5,-4))\n",
    "\n",
    "        # BBB\n",
    "        self.bias_rho = nn.Parameter(torch.Tensor(out_features).normal_(-8, .05))\n",
    "    \n",
    "\n",
    "        self.bias = Gaussian(self.bias_mu, self.bias_rho)\n",
    "\n",
    "        # Prior distributions\n",
    "        if self.mixture:\n",
    "            self.weight_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
    "            self.bias_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
    "        else:\n",
    "            self.weight_prior = ScaleGaussian(PI, SIGMA_1)\n",
    "            self.bias_prior = ScaleGaussian(PI, SIGMA_1)\n",
    "        \n",
    "        self.log_prior = 0\n",
    "        self.log_variational_posterior = 0\n",
    "\n",
    "    def forward(self, input, sample=False, calculate_log_probs=False):\n",
    "        if self.training or sample:\n",
    "            weight = self.weight.sample()\n",
    "            bias = self.bias.sample()\n",
    "        else:\n",
    "            weight = self.weight.mu\n",
    "            bias = self.bias.mu\n",
    "        if self.training or calculate_log_probs:\n",
    "            self.log_prior = self.weight_prior.log_prob(weight) + self.bias_prior.log_prob(bias)\n",
    "            self.log_variational_posterior = self.weight.log_prob(weight) + self.bias.log_prob(bias)\n",
    "        else:\n",
    "            self.log_prior, self.log_variational_posterior = 0, 0\n",
    "\n",
    "        return F.linear(input, weight, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "itSuNJtYo-X7"
   },
   "outputs": [],
   "source": [
    "class BayesianNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # for breast 28*28 and OUT 2\n",
    "        # for MNIST and FMINSt 28*28 and OUT 10\n",
    "        self.l1 = BayesianLinear(28*28, 400, True)\n",
    "        self.l2 = BayesianLinear(400, 400, True)\n",
    "        self.l3 = BayesianLinear(400, 10, True)\n",
    "    \n",
    "    def forward(self, x, sample=False):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.l1(x, sample))\n",
    "        x = F.relu(self.l2(x, sample))\n",
    "        x = F.log_softmax(self.l3(x, sample), dim=1)\n",
    "        return x\n",
    "    \n",
    "    def log_prior(self):\n",
    "        return self.l1.log_prior \\\n",
    "               + self.l2.log_prior \\\n",
    "               + self.l3.log_prior\n",
    "    \n",
    "    def log_variational_posterior(self):\n",
    "        return self.l1.log_variational_posterior \\\n",
    "               + self.l2.log_variational_posterior \\\n",
    "               + self.l3.log_variational_posterior\n",
    "    \n",
    "    def sample_elbo(self, input, target, samples=SAMPLES):\n",
    "        \n",
    "        outputs = torch.zeros(samples, BATCH_SIZE, CLASSES).to(DEVICE)\n",
    "        log_priors = torch.zeros(samples).to(DEVICE)\n",
    "        log_variational_posteriors = torch.zeros(samples).to(DEVICE)\n",
    "        for i in range(samples):\n",
    "            outputs[i] = self(input, sample=True)\n",
    "            log_priors[i] = self.log_prior()\n",
    "            log_variational_posteriors[i] = self.log_variational_posterior()\n",
    "        log_prior = log_priors.mean()\n",
    "        log_variational_posterior = log_variational_posteriors.mean()\n",
    "        negative_log_likelihood = F.nll_loss(outputs.mean(0), target, size_average=False)\n",
    "        loss = (log_variational_posterior - log_prior)/NUM_BATCHES + negative_log_likelihood\n",
    "        return loss, log_prior, log_variational_posterior, negative_log_likelihood\n",
    "\n",
    "net = BayesianNetwork().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h-HLpkfPm2BI"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q31y405kpGxt"
   },
   "outputs": [],
   "source": [
    "def train(net, optimizer, epoch):\n",
    "    net.train()\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        target = target.squeeze().long()\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        net.zero_grad()\n",
    "        loss, log_prior, log_variational_posterior, negative_log_likelihood = net.sample_elbo(data, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, samples):\n",
    "    correct = 0\n",
    "    for idx, (data, target) in enumerate(loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        if samples == 1:\n",
    "            output = model(data, sample=False).to(DEVICE)\n",
    "        else:\n",
    "            outputs = torch.zeros(samples, TEST_BATCH_SIZE, CLASSES).to(DEVICE)\n",
    "            for i in range(samples):\n",
    "                outputs[i] = model(data, sample=True)\n",
    "            output = outputs.mean(0)\n",
    "\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1090232,
     "status": "ok",
     "timestamp": 1528264929340,
     "user": {
      "displayName": "Nitarshan Rajkumar",
      "photoUrl": "//lh6.googleusercontent.com/-oLz5q0aJmAQ/AAAAAAAAAAI/AAAAAAAAAIY/O0-NjvATt18/s50-c-k-no/photo.jpg",
      "userId": "117587045527370134083"
     },
     "user_tz": 420
    },
    "id": "cWaZ4c93pJkm",
    "outputId": "379e274f-ac3b-406b-9d31-c1a760242f84"
   },
   "outputs": [],
   "source": [
    "#optimizer = optim.Adam(net.parameters())\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-4, momentum=0.95)\n",
    "\n",
    "test_accs_ens = np.zeros(300)\n",
    "test_accs_mean = np.zeros(300)\n",
    "\n",
    "for epoch in range(300):\n",
    "    train(net, optimizer, epoch)\n",
    "\n",
    "    test_acc_ens = evaluate(net, test_loader, samples=10)\n",
    "    test_acc_mean = evaluate(net, test_loader, samples=1)\n",
    "    test_accs_ens[epoch] = test_acc_ens\n",
    "    test_accs_mean[epoch] = test_acc_mean\n",
    "    print('Epoch: ', epoch)\n",
    "    print('Test acc ens: ', test_acc_ens)\n",
    "    print('Test acc mean: ', test_acc_mean)\n",
    "\n",
    "    if epoch%25 == 0:\n",
    "        path = 'Results/BBB-mixture/BBB_mnist_400_0.0001_ID0_notebook_epoch_' + str(epoch)\n",
    "        torch.save(net.state_dict(), path + '.pth')\n",
    "\n",
    "path = 'Results/BBB-mixture/BBB_mnist_400_0.0001_ID0_notebook_epoch_' + str(epoch)\n",
    "torch.save(net.state_dict(), path + '.pth')\n",
    "\n",
    " \n",
    "path = 'Results/BBB-mixture/BBB_mnist_400_0.0001_ID0_notebook2'\n",
    "wr = csv.writer(open(path + '.csv', 'w'), delimiter=',', lineterminator='\\n')\n",
    "wr.writerow(['epoch', 'test_acc_ens', 'test_acc_mean'])\n",
    "\n",
    "for i in range(300):\n",
    "    wr.writerow((i + 1, test_accs_ens[i],test_accs_mean[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Results/BBB-mixture/BBB_mnist_400_0.0001_ID0_notebook2'\n",
    "wr = csv.writer(open(path + '.csv', 'w'), delimiter=',', lineterminator='\\n')\n",
    "wr.writerow(['epoch', 'test_acc_ens', 'test_acc_mean'])\n",
    "\n",
    "for i in range(200):\n",
    "    wr.writerow((i + 1, test_accs_ens[i],test_accs_mean[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN = 1200\n",
    "modelpath = \"Results/all-in-bbb/BBB_mnist_1200_0.0001_ID0_notebook_epoch_299.pth\"\n",
    "\n",
    "model = BayesianNetwork()\n",
    "\n",
    "model.load_state_dict(torch.load(modelpath, map_location='cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThreshold(model,buckets):\n",
    "    sigmas = []\n",
    "    mus = []\n",
    "\n",
    "    sigmas.append(model.state_dict()['l1.weight_rho'].view(-1).cpu().detach().numpy())\n",
    "    sigmas.append(model.state_dict()['l2.weight_rho'].view(-1).cpu().detach().numpy())\n",
    "    sigmas.append(model.state_dict()['l3.weight_rho'].view(-1).cpu().detach().numpy())\n",
    "\n",
    "    mus.append(model.state_dict()['l1.weight_mu'].view(-1).cpu().detach().numpy())\n",
    "    mus.append(model.state_dict()['l2.weight_mu'].view(-1).cpu().detach().numpy())\n",
    "    mus.append(model.state_dict()['l3.weight_mu'].view(-1).cpu().detach().numpy())\n",
    "    \n",
    "\n",
    "    sigmas = np.concatenate(sigmas).ravel()\n",
    "    mus = np.concatenate(mus).ravel()\n",
    "    sigmas = np.log(1. + np.exp(sigmas))\n",
    "    sign_to_noise = np.abs(mus) / sigmas\n",
    "    p = np.percentile(sign_to_noise, buckets)\n",
    "    \n",
    "    s = np.log10(sign_to_noise)/10\n",
    "    hist, bin_edges = np.histogram(s, bins='auto')\n",
    "    hist = hist / s.size\n",
    "    X =[]\n",
    "    for i in range(hist.size):\n",
    "        X.append((bin_edges[i]+bin_edges[i+1])*0.5)\n",
    "    \n",
    "    plt.plot(X,hist)\n",
    "    plt.axvline(x= np.log10(p[4])/10, color='red')\n",
    "    plt.ylabel('Density')\n",
    "    plt.xlabel('Signal−to−Noise Ratio (dB)')\n",
    "    plt.savefig('./Results/SignalToNoiseRatioDensity_BBB_mnist_1200_0.0001_ID0_notebook_epoch_299.png')\n",
    "    plt.savefig('./Results/SignalToNoiseRatioDensity_BBB_mnist_1200_0.0001_ID0_notebook_epoch_299.eps', format='eps', dpi=1000)\n",
    "\n",
    "    plt.figure(2)\n",
    "    Y = np.cumsum(hist)\n",
    "    plt.plot(X, Y)\n",
    "    plt.axvline(x= np.log10(p[4])/10, color='red')\n",
    "    plt.hlines(y= 0.75, xmin=np.min(s),xmax=np.max(s),colors='red')\n",
    "    plt.ylabel('CDF')\n",
    "    plt.xlabel('Signal−to−Noise Ratio (dB)')\n",
    "    plt.savefig('./Results/SignalToNoiseRatioDensity_CDF_BBB_mnist_1200_0.0001_ID0_notebook_epoch_299.png')\n",
    "    plt.savefig('./Results/SignalToNoiseRatioDensity_CDF_BBB_mnist_1200_0.0001_ID0_notebook_epoch_299.eps', format='eps', dpi=1000)\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = np.asarray([0,10,25,50,75,95,98])\n",
    "thresholds = getThreshold(model,buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from torch.autograd import Variable\n",
    "\n",
    "model_name = \"BBB_mnist_1200_0.0001_ID0_notebook_epoch_299\"\n",
    "\n",
    "for index in range(buckets.size):\n",
    "    print(buckets[index],'-->',thresholds[index])\n",
    "    t = Variable(torch.Tensor([thresholds[index]]))\n",
    "    model1 = copy.deepcopy(model)\n",
    "    for i in range(1, 4):\n",
    "        rho = model.state_dict()['l'+str(i)+'.weight_rho']\n",
    "        mu = model.state_dict()['l'+str(i)+'.weight_mu'] \n",
    "        sigma = np.log(1. + np.exp(rho.cpu().numpy()))\n",
    "        signalRatio = np.abs(mu.cpu().numpy()) / sigma\n",
    "        signalRatio = (torch.from_numpy(signalRatio) > t).float() * 1\n",
    "        model1.state_dict()['l'+str(i)+'.weight_rho'].data.copy_(rho * signalRatio)\n",
    "        model1.state_dict()['l'+str(i)+'.weight_mu'].data.copy_(mu * signalRatio)\n",
    "\n",
    "    torch.save(model1.state_dict(), 'Models/' + model_name + '_Pruned_'+str(buckets[index])+'.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate pruned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for root, dirs, files in os.walk(\"Models/all-in-bbb-pruned\"):\n",
    "    for file in files:\n",
    "        if file.startswith('BBB_mnist_1200') and file.endswith(\".pth\"):\n",
    "            print(file)\n",
    "            pruned_model = BayesianNetwork().to(DEVICE)\n",
    "            pruned_model.load_state_dict(torch.load('Models/all-in-bbb-pruned/' + file))\n",
    "            pruned_model.eval()\n",
    "\n",
    "            correct = 0\n",
    "            corrects = np.zeros(TEST_SAMPLES+1, dtype=int)\n",
    "            with torch.no_grad():\n",
    "                for data, target in test_loader:\n",
    "                    data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                    outputs = torch.zeros(TEST_SAMPLES+1, TEST_BATCH_SIZE, CLASSES).to(DEVICE)\n",
    "                    for i in range(TEST_SAMPLES):\n",
    "                        outputs[i] = pruned_model(data, sample=True)\n",
    "                    outputs[TEST_SAMPLES] = pruned_model(data, sample=False)\n",
    "                    output = outputs.mean(0)\n",
    "                    preds = preds = outputs.max(2, keepdim=True)[1]\n",
    "                    pred = output.max(1, keepdim=True)[1] # index of max log-probability\n",
    "                    corrects += preds.eq(target.view_as(pred)).sum(dim=1).squeeze().cpu().numpy()\n",
    "                    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            for index, num in enumerate(corrects):\n",
    "                if index < TEST_SAMPLES:\n",
    "                    print('Component {} Accuracy: {}/{}'.format(index, num, TEST_SIZE))\n",
    "                else:\n",
    "                    print('Posterior Mean Accuracy: {}/{}'.format(num, TEST_SIZE))\n",
    "            print('Ensemble Accuracy: {}/{}'.format(correct, TEST_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "from SGD import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE = 1000\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        './mnist', train=False, download=True,\n",
    "        transform=transforms.ToTensor()),\n",
    "    batch_size=TEST_BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = ModelMLPDropout(400, n_input=28*28, n_ouput=10)\n",
    "modelpath3 = 'Results/SGD/SGD_mnist_dropout_400_0.001_0.95.pth'\n",
    "model3.load_state_dict(torch.load(modelpath3, map_location='cpu'))\n",
    "#model3.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters_to_prune = (\n",
    "    (model3.fc0, 'weight'),\n",
    "    (model3.fc1, 'weight'),\n",
    "    (model3.fc2, 'weight'),\n",
    ")\n",
    "\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    #pruning_method=prune.L1Unstructured,\n",
    "    pruning_method=prune.random_unstructured,\n",
    "    amount=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Sparsity in fc0.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model3.fc0.weight == 0))\n",
    "        / float(model3.fc0.weight.nelement())\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Sparsity in fc1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model3.fc1.weight == 0))\n",
    "        / float(model3.fc1.weight.nelement())\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Sparsity in fc2.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model3.fc2.weight == 0))\n",
    "        / float(model3.fc2.weight.nelement())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    acc_sum = 0\n",
    "    #DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    for idx, (data, target) in enumerate(loader):\n",
    "        #data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        predict = output.data.max(1)[1]\n",
    "        acc = predict.eq(target.data).cpu().sum().item()\n",
    "        acc_sum += acc\n",
    "    return loss_sum / len(loader), acc_sum / len(loader)\n",
    "\n",
    "test_loss, test_acc = evaluate(model3, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_weights(model, bnn=False, dvi = False, lrt=False):\n",
    "    '''Collect all weights from model in a list'''\n",
    "    mus = []\n",
    "    rhos = []\n",
    "    weights = []\n",
    "    stds=[]\n",
    "    if lrt:\n",
    "        for name, param in model.net.named_parameters():\n",
    "            if 'mu' in name:\n",
    "                mus.append(param.flatten().tolist())\n",
    "            elif 'rho' in name:\n",
    "                rhos.append(param.flatten().tolist())\n",
    "            else:\n",
    "                weights.append(param.flatten().tolist())\n",
    "    else:\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'mu' in name:\n",
    "                mus.append(param.flatten().tolist())\n",
    "            elif 'rho' in name:\n",
    "                rhos.append(param.flatten().tolist())\n",
    "\n",
    "            elif 'W' in name:\n",
    "                if 'log' in name:\n",
    "                    stds.append(param.flatten().tolist())\n",
    "                else:\n",
    "                    mus.append(param.flatten().tolist())\n",
    "            else:\n",
    "                weights.append(param.flatten().tolist())\n",
    "    \n",
    "    # flatten nested lists\n",
    "    mus = [item for sublist in mus for item in sublist]\n",
    "    rhos = [item for sublist in rhos for item in sublist]\n",
    "    weights = [item for sublist in weights for item in sublist]\n",
    "    stds = [item for sublist in stds for item in sublist]\n",
    "\n",
    "    if bnn:\n",
    "        sigmas = [rho_to_sigma(rho) for rho in rhos]\n",
    "        weights = [mus, sigmas]\n",
    "\n",
    "    if dvi:\n",
    "        weights = [mus, stds]\n",
    "\n",
    "    return weights\n",
    "\n",
    "def rho_to_sigma(rho): \n",
    "    return np.log(1 + np.exp(rho))\n",
    "\n",
    "def sample_bnn_weights(mu, sigma):\n",
    "    return np.random.normal(mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SGD import *\n",
    "\n",
    "\n",
    "models = []\n",
    "\n",
    "\n",
    "model0 = BayesianNetwork()\n",
    "modelpath0 = 'mnist_400_sgd_constant_xavier_neg2_epoch_400.pth'\n",
    "model0.load_state_dict(torch.load(modelpath0, map_location='cpu'))\n",
    "model0.eval()\n",
    "models.append(model0)\n",
    "\n",
    "\n",
    "model2 = ModelMLP(400, n_input=28*28, n_ouput=10)\n",
    "modelpath2 = 'Results/SGD/SGD_mnist_mlp_400_0.001_0.95.pth'\n",
    "model2.net.state_dict(torch.load(modelpath2, map_location='cpu'))\n",
    "model2.eval()\n",
    "models.append(model2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn_mus, bnn_sigmas = collect_weights(model0, bnn=True)\n",
    "bnn_weights = [sample_bnn_weights(mu, sigma) for mu, sigma in zip(bnn_mus, bnn_sigmas)]\n",
    "\n",
    "mlp_weights = collect_weights(model2, lrt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(weights_list, labels):\n",
    "    plt.style.use('seaborn-colorblind')\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    colors = ['cornflowerblue',  '#ffb266', '#7f00ff' ]\n",
    "    index = 0\n",
    "\n",
    "    for weights, label in zip(weights_list, labels):\n",
    "        sns.kdeplot(weights, label=label, fill=True, clip=[-0.7, 0.7], color = colors[index])\n",
    "        index+=1\n",
    "    plt.xlim(-0.7, 0.7)\n",
    "    plt.ylabel('Probability Density', fontsize=20)\n",
    "    plt.xlabel('Weight', fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.legend(loc=2, prop={'size': 18})\n",
    "    #plt.savefig('weight_histogram.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(\n",
    "        [ mlp_weights,  bnn_weights], \n",
    "        ['Vanilla SGD',  'BBB']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "columns = [\"test_acc\"]\n",
    "columns2 = [\"test_acc_ens\"]\n",
    "df_1 = pd.read_csv(\"Results/SGD/SGD_mnist_dropout_400_0.001_0.95.csv\", usecols=columns)\n",
    "df_2 = pd.read_csv(\"Results/SGD/SGD_mnist_mlp_400_0.001_0.95.csv\", usecols=columns)\n",
    "df_3 = pd.read_csv(\"Results/BBB_mnist_400_ 2 copy.csv\", usecols=[\"test_acc_new\"])\n",
    "\n",
    "colors = ['#7f00ff','cornflowerblue',  '#ffb266' ]\n",
    "plt.style.use('seaborn-colorblind')\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(df_2.test_acc*100, label = 'Vanilla SGD', linewidth=2, color = 'cornflowerblue')\n",
    "plt.plot(df_1.test_acc*100, label = 'Dropout SGD', linewidth=2, color = '#ffb266')\n",
    "plt.plot((1-df_3.test_acc_new)*100, label = 'BBB', linewidth=2, color = '#7f00ff')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.ylabel('Test error (%)', fontsize=20)\n",
    "\n",
    "plt.xlabel('Epoch', fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "#plt.ylim((1,3))\n",
    "plt.legend(loc=1, prop={'size': 18})\n",
    "plt.savefig('epoch evolution.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "bayes-by-backprop.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
