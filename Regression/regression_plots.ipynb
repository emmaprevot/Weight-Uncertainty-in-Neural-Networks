{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "#sys.path.append('../')\n",
    "from BayesBackpropagation_OG import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare Network\n",
    "\n",
    "#Hyperparameter setting\n",
    "\n",
    "SAMPLES = 5\n",
    "TEST_SAMPLES = 10\n",
    "BATCH_SIZE = 200\n",
    "NUM_BATCHES = 10\n",
    "TEST_BATCH_SIZE = 75\n",
    "CLASSES = 1\n",
    "PI = 0.25\n",
    "SIGMA_1 = torch.FloatTensor([math.exp(-0)])\n",
    "SIGMA_2 = torch.FloatTensor([math.exp(-6)])\n",
    "\n",
    "net = BayesianNetwork(inputSize = 1,\\\n",
    "                        CLASSES = CLASSES, \\\n",
    "                        layers=np.array([16,16, 16]), \\\n",
    "                        activations = np.array(['relu', 'relu','relu','none']), \\\n",
    "                        SAMPLES = SAMPLES, \\\n",
    "                        BATCH_SIZE = BATCH_SIZE,\\\n",
    "                        NUM_BATCHES = NUM_BATCHES,\\\n",
    "                        hasScalarMixturePrior = True,\\\n",
    "                        PI = PI,\\\n",
    "                        SIGMA_1 = SIGMA_1,\\\n",
    "                        SIGMA_2 = SIGMA_2,\\\n",
    "                        GOOGLE_INIT= False)\n",
    "    \n",
    "\n",
    "\n",
    "modelpath = \"Models/Regression_BBB_cont_homo_10000.pth\"\n",
    "\n",
    "net.load_state_dict(torch.load(modelpath, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "        def __init__(self, n_feature, n_hidden, n_output):\n",
    "            super(Net, self).__init__()\n",
    "            self.l1 = torch.nn.Linear(n_feature, n_hidden)   \n",
    "            self.l2 =  torch.nn.Linear(n_hidden, n_hidden)   \n",
    "            self.l3 =  torch.nn.Linear(n_hidden, n_hidden)  \n",
    "            self.predict = torch.nn.Linear(n_hidden, n_output)   \n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.l1(x))      \n",
    "            x = F.relu(self.l2(x))      \n",
    "            x = F.relu(self.l3(x))      \n",
    "            x = self.predict(x)         \n",
    "            return x\n",
    "\n",
    "net_NN = Net(n_feature=1, n_hidden=16, n_output=1)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n",
    "\n",
    "modelpath = \"Models/new_data_range/Regression_NN_cont_homo.pth\"\n",
    "\n",
    "net_NN.load_state_dict(torch.load(modelpath, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generation \n",
    "\n",
    "# continuous data range\n",
    "x = np.random.uniform(-0.5, 0.5, size=(NUM_BATCHES,BATCH_SIZE))\n",
    "x_test = np.linspace(-1, 1,TEST_BATCH_SIZE)\n",
    "\n",
    "# split cluster\n",
    "# un-comment this to investigate split cluster data range\n",
    "'''\n",
    "x = np.random.uniform(-0.5, 0.5, size=(NUM_BATCHES,BATCH_SIZE))\n",
    "for i in range(x.shape[0]):\n",
    "    for j in range(x.shape[1]):\n",
    "        if x[i][j]>0:\n",
    "            x[i][j] += 0.5\n",
    "\n",
    "x_test = np.linspace(-1, 1.5, 75)\n",
    "\n",
    "'''\n",
    "\n",
    "noise = np.random.normal(0, 0.02, size=(NUM_BATCHES,BATCH_SIZE)) #metric as mentioned in the paper\n",
    "def noise_model(x):\n",
    "    return 0.45*(x+0.5)**2\n",
    "\n",
    "# HOMOSKEDASTIC REGRESSION from BLUNDELL15\n",
    "y = x + 0.3*np.sin(2*np.pi*(x+noise)) + 0.3*np.sin(4*np.pi*(x+noise)) + noise\n",
    "y_test = x_test + 0.3*np.sin(2*np.pi*x_test) + 0.3*np.sin(4*np.pi*x_test)\n",
    "\n",
    "# HETEROSKEDASTIC REGRESSION\n",
    "#y_test = -(x_test+0.5)*np.sin(3 * np.pi *x_test)\n",
    "#y = -(x+0.5)*np.sin(3 * np.pi *x) + np.random.normal(0, noise_model(x))\n",
    "\n",
    "Var = lambda x, dtype=torch.FloatTensor: Variable(torch.from_numpy(x).type(dtype)) #converting data to tensor\n",
    "X = Var(x)\n",
    "Y = Var(y)\n",
    "X_test = Var(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing BBB\n",
    "outputs = torch.zeros(TEST_SAMPLES+1, TEST_BATCH_SIZE, CLASSES)\n",
    "for i in range(TEST_SAMPLES):\n",
    "    outputs[i] = net.forward(X_test)\n",
    "outputs[TEST_SAMPLES] = net.forward(X_test)\n",
    "pred_mean = outputs.mean(0).data.cpu().numpy().squeeze(1) #Compute mean prediction\n",
    "pred_std = outputs.std(0).data.cpu().numpy().squeeze(1) #Compute standard deviation of prediction for each data point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing NN\n",
    "\n",
    "x = x.flatten()\n",
    "X = Var(x)\n",
    "X = torch.unsqueeze(X,1)\n",
    "    \n",
    "y = y.flatten()\n",
    "Y = Var(y)\n",
    "Y = torch.unsqueeze(Y,1)\n",
    "X_test_NN = Var(x_test)\n",
    "X_test_NN = torch.unsqueeze(X_test_NN,1)\n",
    "\n",
    "\n",
    "prediction = net_NN(X_test_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Visualization BB\n",
    "plt.fill_between(x_test, pred_mean - 2 * pred_std, pred_mean + 2 * pred_std,\n",
    "                        color='cornflowerblue', alpha=.5, label='+/- 2 std')\n",
    "plt.scatter(x, y, s = 1,c='black', label='target', alpha = 0.2)\n",
    "plt.ylim([-4, 4])\n",
    "#plt.ylabel(\"y\")\n",
    "#plt.xlabel(\"x\")\n",
    "plt.plot(x_test, pred_mean, c='red', label='Prediction')\n",
    "plt.plot(x_test, y_test, c='grey', label='Ground Truth')\n",
    "#plt.title(\"BBB Mixture\")\n",
    "#plt.legend()\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Results/new_data_range/Regression_BBB_base_paper9_1000.png')\n",
    "#plt.savefig('Results/Regression_BBB_128_3_wu.eps', format='eps', dpi=1000)\n",
    "#plt.clf()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization NN\n",
    "plt.scatter(x, y,s=1.5, c='black', label='target', alpha = 0.5)\n",
    "plt.plot(x_test, prediction.detach().numpy(), c='red', label='Prediction')\n",
    "plt.plot(x_test, y_test, c='grey', label='Ground Truth')\n",
    "plt.ylim([-3, 3])\n",
    "#plt.title(\"Neural Network\")\n",
    "#plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('Results/new_data_range/Regression_NN_base_paper9_2000.png')\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('Results/Regression_NN_128_3_wu.eps', format='eps', dpi=1000)\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
